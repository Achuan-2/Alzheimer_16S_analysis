```{r}
rm(list = ls())
library(tidyverse)
library(stringr)
otu <- read.table("./data/table_genus.tsv", header = TRUE, row.names = 1, sep = "\t", fill = TRUE)
## 过滤注释有问题的特征（
otu <- filter(otu, !grepl(";__|uncultured", rownames(otu)))
# 精简物种注释
rownames(otu) <- sapply(str_split(rownames(otu), "__"), "[", 7)
# 随机森林模型数据需要归一化吗？
# 随机森林的逻辑是基于决策树模型多棵树模型，内部采用boostrap抽样训练多棵树，然后做bagging预测提高其精度，决策树模型具体实现机制以一定区别，不过一般是基于排序的划分，所以一般不需要进行归一化处理。
# ！过滤低丰度 OTUs 类群，它们对分类贡献度低，且影响计算效率
# 171 个样本，就按 OTUs 丰度的行和不小于 171 为准吧
dim(otu) # 208 171
otu <- otu[which(rowSums(otu) >= 171), ]
dim(otu) # 172 171
# 合并分组，得到能够被 randomForest 识别计算的格式
group <- read.table("./data/metadata.txt",
    sep = "\t", row.names = 1,
    header = TRUE, fill = TRUE
)
genus <- read.table("./data/significance_genus.txt", header = TRUE)
otu_signi<-otu[genus$var, ]
# View(otu_signi)
otu1 <- data.frame(t(otu_signi))
otu_group <- cbind(otu1, group)
```

```{r}
# 将总数据集分为训练集（占 70%）和测试集（占 30%）
set.seed(171)
select_train <- sample(171, 171 * 0.5)
otu_train <- otu_group[select_train, ] # 85
dim(otu_train)
otu_test <- otu_group[-select_train, ] # 86
dim(otu_test)
####################################################
# randomForest 包的随机森林
library(randomForest)
# 随机森林计算（默认生成 500 棵决策树），详情 ?randomForest
set.seed(123)

otu_train_forest <- randomForest(
    as.factor(Group) ~ .,
    data = otu_train,
    importance = TRUE
)
otu_train_forest

plot(randomForest::margin(otu_train_forest), main = "观测值被判断正确的概率图")


# 训练集自身测试
train_predict <- predict(otu_train_forest, otu_train)
# table 可以直接搞出预测和实际的混淆矩阵
compare_train <- table(
    train_predict, otu_train$Group,
    dnn = c("Actual", "Predicted")
)
compare_train
```

No. of variables tried at each split: 3

        OOB estimate of  error rate: 25.88%
Confusion matrix:
   AD  C class.error
AD 38 10   0.2083333
C  12 25   0.3243243
There were 37 warnings (use warnings() to see them)
      Predicted
Actual AD  C
    AD 48  0
    C   0 37



使用测试集评估
```{r}
test_predict <- predict(otu_train_forest, otu_test)
compare_test <- table(
    otu_test$Group,
    test_predict,
    dnn = c("Actual", "Predicted")
)
compare_test
sum(diag(compare_test) / sum(compare_test))
pred_rf_all <- predict(otu_train_forest, otu_test, type = "prob")
```
      Predicted
Actual AD  C
    AD 42 10
    C   9 25
[1] 0.7790698

```{r}
library(pROC)
load("data.RData")
roc_genus <- roc(
    otu_test$Group, pred_rf_all[, 2],
    # plot = TRUE,
    # legacy.axes = TRUE, percent = TRUE, xlab = "False Positive Percentage", ylab = "True Postive Percentage", col = "#377eb8",
    # lwd = 3, print.auc = TRUE, auc.polygon = TRUE, auc.polygon.col = "#377eb83f"
)
#  roc 0.8795
c("s"*2)



sensitivities<-c(roc_genus$sensitivities, roc_simpl$sensitivities)
FRR<-c(1 - roc_genus$specificities, 1 - roc_simpl$specificities)
group <- c(
    rep("Significant features（AUC=0.85）", length(roc_genus$sensitivities)),
    rep("Classifiers features（AUC=0.88）", length(roc_simpl$sensitivities))
)
mydata <- data.frame(sensitivities, FRR,group)
p <- ggplot(mydata, aes(x = FRR, y = sensitivities, colour = group, group =group, fill = group)) +
    geom_line(size = 1) +xlab("1 - specificity") + theme_bw() + scale_fill_discrete(
        name = "Experimental\nCondition",
        breaks = c("ctrl", "trt1", "trt2"),
        labels = c("Control", "Treatment 1", "Treatment 2")
    )+scale_color_manual(values = c("orange","#009194"))
p


ggsave("plot/roc.svg", p,
    width = 10,
    height = 5
)
```

```{r}
confusion_matrix <- as.matrix(compare_test)
library(pheatmap)
pheatmap(
    confusion_matrix,
    cluster_cols = FALSE,
    cluster_rows = FALSE,
    legend = FALSE,
    display_numbers = TRUE,
    number_format = "%1d",
    cellwidth = 60, cellheight = 60,
    color = c("#f5fafa", "#cee4e5", "#009194"),
    fontsize = 10,
    filename = "plot/confusion_matrix.pdf"
)
```